from lisa.lisa_pipeline import LISAPipeline
from PIL import Image
import os
from tqdm import tqdm
lisa_model_type = "xinlai/LISA-7B-v1-explanatory"
lisa_conv_type = "llava_llama_2"
lisa_pipeline = LISAPipeline(lisa_model_type, local_rank=0, load_in_4bit=False, load_in_8bit=True, conv_type=lisa_conv_type)


images_root = 'data/nerf_llff_data/room/images_4'
image_names = os.listdir(images_root)
image_names = [image_name for idx, image_name in enumerate(image_names) if idx % 8 == 0]
image_paths = [os.path.join(images_root, image_name) for image_name in image_names]
prompt = 'what can be used to play videos'
lisa_text_prompt = f'Can you segment {prompt}?'
save_path = f'output/lisa/room/{prompt}'
os.makedirs(save_path, exist_ok=True)
# image_names = os.listdir(images_root)
# image_paths = [os.path.join(images_root, name) for name in image_names]
# images = [Image.open(path) for path in image_paths]



image_names


for i in tqdm(range(len(image_paths))):
    image_name = image_names[i]
    image_path = image_paths[i]
    image = Image.open(image_path)
    result_list, mask_result_list, mask_list, mask_rgb_list, output_str = lisa_pipeline(lisa_text_prompt, image=image)
    save_name = image_name.split('.')[0] + '.png'
    Image.fromarray(mask_list[0]).save(os.path.join(save_path, save_name))
    


result_list, mask_result_list, mask_list, mask_rgb_list, output_str = lisa_pipeline(lisa_text_prompt, image=images[0])


mask_list[0].shape


Image.fromarray(mask_list[0])



