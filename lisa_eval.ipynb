{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "We couldn't connect to 'https://huggingface.co' to load this file, couldn't find it in the cached files and it looks like xinlai/LISA-7B-v1-explanatory is not the path to a directory containing a file named config.json.\nCheckout your internet connection or see how to run the library in offline mode at 'https://huggingface.co/docs/transformers/installation#offline-mode'.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOfflineModeIsEnabled\u001b[0m                      Traceback (most recent call last)",
      "File \u001b[0;32m/media/guest/Elephant/conda_space/envs/3dgs/lib/python3.10/site-packages/huggingface_hub/file_download.py:1261\u001b[0m, in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, local_dir_use_symlinks, user_agent, force_download, force_filename, proxies, etag_timeout, resume_download, token, local_files_only, headers, legacy_cache_layout, endpoint)\u001b[0m\n\u001b[1;32m   1260\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1261\u001b[0m     metadata \u001b[39m=\u001b[39m get_hf_file_metadata(\n\u001b[1;32m   1262\u001b[0m         url\u001b[39m=\u001b[39;49murl,\n\u001b[1;32m   1263\u001b[0m         token\u001b[39m=\u001b[39;49mtoken,\n\u001b[1;32m   1264\u001b[0m         proxies\u001b[39m=\u001b[39;49mproxies,\n\u001b[1;32m   1265\u001b[0m         timeout\u001b[39m=\u001b[39;49metag_timeout,\n\u001b[1;32m   1266\u001b[0m         library_name\u001b[39m=\u001b[39;49mlibrary_name,\n\u001b[1;32m   1267\u001b[0m         library_version\u001b[39m=\u001b[39;49mlibrary_version,\n\u001b[1;32m   1268\u001b[0m         user_agent\u001b[39m=\u001b[39;49muser_agent,\n\u001b[1;32m   1269\u001b[0m     )\n\u001b[1;32m   1270\u001b[0m \u001b[39mexcept\u001b[39;00m EntryNotFoundError \u001b[39mas\u001b[39;00m http_error:\n\u001b[1;32m   1271\u001b[0m     \u001b[39m# Cache the non-existence of the file and raise\u001b[39;00m\n",
      "File \u001b[0;32m/media/guest/Elephant/conda_space/envs/3dgs/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py:119\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    117\u001b[0m     kwargs \u001b[39m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[39m=\u001b[39mfn\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, has_token\u001b[39m=\u001b[39mhas_token, kwargs\u001b[39m=\u001b[39mkwargs)\n\u001b[0;32m--> 119\u001b[0m \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/media/guest/Elephant/conda_space/envs/3dgs/lib/python3.10/site-packages/huggingface_hub/file_download.py:1674\u001b[0m, in \u001b[0;36mget_hf_file_metadata\u001b[0;34m(url, token, proxies, timeout, library_name, library_version, user_agent, headers)\u001b[0m\n\u001b[1;32m   1673\u001b[0m \u001b[39m# Retrieve metadata\u001b[39;00m\n\u001b[0;32m-> 1674\u001b[0m r \u001b[39m=\u001b[39m _request_wrapper(\n\u001b[1;32m   1675\u001b[0m     method\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mHEAD\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m   1676\u001b[0m     url\u001b[39m=\u001b[39;49murl,\n\u001b[1;32m   1677\u001b[0m     headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m   1678\u001b[0m     allow_redirects\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m   1679\u001b[0m     follow_relative_redirects\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m   1680\u001b[0m     proxies\u001b[39m=\u001b[39;49mproxies,\n\u001b[1;32m   1681\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m   1682\u001b[0m )\n\u001b[1;32m   1683\u001b[0m hf_raise_for_status(r)\n",
      "File \u001b[0;32m/media/guest/Elephant/conda_space/envs/3dgs/lib/python3.10/site-packages/huggingface_hub/file_download.py:369\u001b[0m, in \u001b[0;36m_request_wrapper\u001b[0;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[1;32m    368\u001b[0m \u001b[39mif\u001b[39;00m follow_relative_redirects:\n\u001b[0;32m--> 369\u001b[0m     response \u001b[39m=\u001b[39m _request_wrapper(\n\u001b[1;32m    370\u001b[0m         method\u001b[39m=\u001b[39;49mmethod,\n\u001b[1;32m    371\u001b[0m         url\u001b[39m=\u001b[39;49murl,\n\u001b[1;32m    372\u001b[0m         follow_relative_redirects\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    373\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mparams,\n\u001b[1;32m    374\u001b[0m     )\n\u001b[1;32m    376\u001b[0m     \u001b[39m# If redirection, we redirect only relative paths.\u001b[39;00m\n\u001b[1;32m    377\u001b[0m     \u001b[39m# This is useful in case of a renamed repository.\u001b[39;00m\n",
      "File \u001b[0;32m/media/guest/Elephant/conda_space/envs/3dgs/lib/python3.10/site-packages/huggingface_hub/file_download.py:392\u001b[0m, in \u001b[0;36m_request_wrapper\u001b[0;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[39m# Perform request and return if status_code is not in the retry list.\u001b[39;00m\n\u001b[0;32m--> 392\u001b[0m response \u001b[39m=\u001b[39m get_session()\u001b[39m.\u001b[39;49mrequest(method\u001b[39m=\u001b[39;49mmethod, url\u001b[39m=\u001b[39;49murl, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mparams)\n\u001b[1;32m    393\u001b[0m hf_raise_for_status(response)\n",
      "File \u001b[0;32m/media/guest/Elephant/conda_space/envs/3dgs/lib/python3.10/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[39m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(prep, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49msend_kwargs)\n\u001b[1;32m    591\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m/media/guest/Elephant/conda_space/envs/3dgs/lib/python3.10/site-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    702\u001b[0m \u001b[39m# Send the request\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m r \u001b[39m=\u001b[39m adapter\u001b[39m.\u001b[39;49msend(request, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    705\u001b[0m \u001b[39m# Total elapsed time of the request (approximately)\u001b[39;00m\n",
      "File \u001b[0;32m/media/guest/Elephant/conda_space/envs/3dgs/lib/python3.10/site-packages/huggingface_hub/utils/_http.py:79\u001b[0m, in \u001b[0;36mOfflineAdapter.send\u001b[0;34m(self, request, *args, **kwargs)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msend\u001b[39m(\u001b[39mself\u001b[39m, request: PreparedRequest, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Response:\n\u001b[0;32m---> 79\u001b[0m     \u001b[39mraise\u001b[39;00m OfflineModeIsEnabled(\n\u001b[1;32m     80\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCannot reach \u001b[39m\u001b[39m{\u001b[39;00mrequest\u001b[39m.\u001b[39murl\u001b[39m}\u001b[39;00m\u001b[39m: offline mode is enabled. To disable it, please unset the `HF_HUB_OFFLINE` environment variable.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     81\u001b[0m     )\n",
      "\u001b[0;31mOfflineModeIsEnabled\u001b[0m: Cannot reach https://huggingface.co/xinlai/LISA-7B-v1-explanatory/resolve/main/config.json: offline mode is enabled. To disable it, please unset the `HF_HUB_OFFLINE` environment variable.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mLocalEntryNotFoundError\u001b[0m                   Traceback (most recent call last)",
      "File \u001b[0;32m/media/guest/Elephant/conda_space/envs/3dgs/lib/python3.10/site-packages/transformers/utils/hub.py:417\u001b[0m, in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, use_auth_token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash)\u001b[0m\n\u001b[1;32m    415\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    416\u001b[0m     \u001b[39m# Load from URL or cache if already cached\u001b[39;00m\n\u001b[0;32m--> 417\u001b[0m     resolved_file \u001b[39m=\u001b[39m hf_hub_download(\n\u001b[1;32m    418\u001b[0m         path_or_repo_id,\n\u001b[1;32m    419\u001b[0m         filename,\n\u001b[1;32m    420\u001b[0m         subfolder\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m \u001b[39mif\u001b[39;49;00m \u001b[39mlen\u001b[39;49m(subfolder) \u001b[39m==\u001b[39;49m \u001b[39m0\u001b[39;49m \u001b[39melse\u001b[39;49;00m subfolder,\n\u001b[1;32m    421\u001b[0m         repo_type\u001b[39m=\u001b[39;49mrepo_type,\n\u001b[1;32m    422\u001b[0m         revision\u001b[39m=\u001b[39;49mrevision,\n\u001b[1;32m    423\u001b[0m         cache_dir\u001b[39m=\u001b[39;49mcache_dir,\n\u001b[1;32m    424\u001b[0m         user_agent\u001b[39m=\u001b[39;49muser_agent,\n\u001b[1;32m    425\u001b[0m         force_download\u001b[39m=\u001b[39;49mforce_download,\n\u001b[1;32m    426\u001b[0m         proxies\u001b[39m=\u001b[39;49mproxies,\n\u001b[1;32m    427\u001b[0m         resume_download\u001b[39m=\u001b[39;49mresume_download,\n\u001b[1;32m    428\u001b[0m         use_auth_token\u001b[39m=\u001b[39;49muse_auth_token,\n\u001b[1;32m    429\u001b[0m         local_files_only\u001b[39m=\u001b[39;49mlocal_files_only,\n\u001b[1;32m    430\u001b[0m     )\n\u001b[1;32m    432\u001b[0m \u001b[39mexcept\u001b[39;00m RepositoryNotFoundError:\n",
      "File \u001b[0;32m/media/guest/Elephant/conda_space/envs/3dgs/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py:119\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    117\u001b[0m     kwargs \u001b[39m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[39m=\u001b[39mfn\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, has_token\u001b[39m=\u001b[39mhas_token, kwargs\u001b[39m=\u001b[39mkwargs)\n\u001b[0;32m--> 119\u001b[0m \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/media/guest/Elephant/conda_space/envs/3dgs/lib/python3.10/site-packages/huggingface_hub/file_download.py:1406\u001b[0m, in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, local_dir_use_symlinks, user_agent, force_download, force_filename, proxies, etag_timeout, resume_download, token, local_files_only, headers, legacy_cache_layout, endpoint)\u001b[0m\n\u001b[1;32m   1404\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1405\u001b[0m         \u001b[39m# Otherwise: most likely a connection issue or Hub downtime => let's warn the user\u001b[39;00m\n\u001b[0;32m-> 1406\u001b[0m         \u001b[39mraise\u001b[39;00m LocalEntryNotFoundError(\n\u001b[1;32m   1407\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mAn error happened while trying to locate the file on the Hub and we cannot find the requested files\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1408\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m in the local cache. Please check your connection and try again or make sure your Internet connection\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1409\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m is on.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1410\u001b[0m         ) \u001b[39mfrom\u001b[39;00m \u001b[39mhead_call_error\u001b[39;00m\n\u001b[1;32m   1412\u001b[0m \u001b[39m# From now on, etag and commit_hash are not None.\u001b[39;00m\n",
      "\u001b[0;31mLocalEntryNotFoundError\u001b[0m: An error happened while trying to locate the file on the Hub and we cannot find the requested files in the local cache. Please check your connection and try again or make sure your Internet connection is on.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m/media/guest/Elephant/YL/instance3dgs/lisa_eval.ipynb Cell 1\u001b[0m line \u001b[0;36m7\n\u001b[1;32m      <a href='vscode-notebook-cell:/media/guest/Elephant/YL/instance3dgs/lisa_eval.ipynb#W0sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m lisa_model_type \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxinlai/LISA-7B-v1-explanatory\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell:/media/guest/Elephant/YL/instance3dgs/lisa_eval.ipynb#W0sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m lisa_conv_type \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mllava_llama_2\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/media/guest/Elephant/YL/instance3dgs/lisa_eval.ipynb#W0sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m lisa_pipeline \u001b[39m=\u001b[39m LISAPipeline(lisa_model_type, local_rank\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m, load_in_4bit\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, load_in_8bit\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, conv_type\u001b[39m=\u001b[39;49mlisa_conv_type)\n",
      "File \u001b[0;32m/media/guest/Elephant/YL/instance3dgs/lisa/lisa_pipeline.py:462\u001b[0m, in \u001b[0;36mLISAPipeline.__init__\u001b[0;34m(self, version, model_max_length, precision, load_in_4bit, load_in_8bit, vision_tower, local_rank, image_size, use_mm_start_end, conv_type)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m,\n\u001b[1;32m    451\u001b[0m              version\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mxinlai/LISA-7B-v1\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m    452\u001b[0m              model_max_length\u001b[39m=\u001b[39m\u001b[39m512\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    459\u001b[0m              use_mm_start_end\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m    460\u001b[0m              conv_type\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mllava_v1\u001b[39m\u001b[39m'\u001b[39m,) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    461\u001b[0m     \u001b[39msuper\u001b[39m(LISAPipeline, \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m()\n\u001b[0;32m--> 462\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtokenizer \u001b[39m=\u001b[39m AutoTokenizer\u001b[39m.\u001b[39;49mfrom_pretrained(\n\u001b[1;32m    463\u001b[0m         version,\n\u001b[1;32m    464\u001b[0m         cache_dir\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    465\u001b[0m         model_max_length\u001b[39m=\u001b[39;49mmodel_max_length,\n\u001b[1;32m    466\u001b[0m         padding_side\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mright\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    467\u001b[0m         use_fast\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, \n\u001b[1;32m    468\u001b[0m     )\n\u001b[1;32m    469\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtokenizer\u001b[39m.\u001b[39mpad_token \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtokenizer\u001b[39m.\u001b[39munk_token\n\u001b[1;32m    470\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mseg_token_idx \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtokenizer(\u001b[39m\"\u001b[39m\u001b[39m[SEG]\u001b[39m\u001b[39m\"\u001b[39m, add_special_tokens\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\u001b[39m.\u001b[39minput_ids[\u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m/media/guest/Elephant/conda_space/envs/3dgs/lib/python3.10/site-packages/transformers/models/auto/tokenization_auto.py:667\u001b[0m, in \u001b[0;36mAutoTokenizer.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    665\u001b[0m \u001b[39mif\u001b[39;00m config_tokenizer_class \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    666\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(config, PretrainedConfig):\n\u001b[0;32m--> 667\u001b[0m         config \u001b[39m=\u001b[39m AutoConfig\u001b[39m.\u001b[39;49mfrom_pretrained(\n\u001b[1;32m    668\u001b[0m             pretrained_model_name_or_path, trust_remote_code\u001b[39m=\u001b[39;49mtrust_remote_code, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[1;32m    669\u001b[0m         )\n\u001b[1;32m    670\u001b[0m     config_tokenizer_class \u001b[39m=\u001b[39m config\u001b[39m.\u001b[39mtokenizer_class\n\u001b[1;32m    671\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(config, \u001b[39m\"\u001b[39m\u001b[39mauto_map\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mAutoTokenizer\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m config\u001b[39m.\u001b[39mauto_map:\n",
      "File \u001b[0;32m/media/guest/Elephant/conda_space/envs/3dgs/lib/python3.10/site-packages/transformers/models/auto/configuration_auto.py:983\u001b[0m, in \u001b[0;36mAutoConfig.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    981\u001b[0m kwargs[\u001b[39m\"\u001b[39m\u001b[39mname_or_path\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m pretrained_model_name_or_path\n\u001b[1;32m    982\u001b[0m trust_remote_code \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mpop(\u001b[39m\"\u001b[39m\u001b[39mtrust_remote_code\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[0;32m--> 983\u001b[0m config_dict, unused_kwargs \u001b[39m=\u001b[39m PretrainedConfig\u001b[39m.\u001b[39;49mget_config_dict(pretrained_model_name_or_path, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    984\u001b[0m has_remote_code \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mauto_map\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m config_dict \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mAutoConfig\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m config_dict[\u001b[39m\"\u001b[39m\u001b[39mauto_map\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m    985\u001b[0m has_local_code \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mmodel_type\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m config_dict \u001b[39mand\u001b[39;00m config_dict[\u001b[39m\"\u001b[39m\u001b[39mmodel_type\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39min\u001b[39;00m CONFIG_MAPPING\n",
      "File \u001b[0;32m/media/guest/Elephant/conda_space/envs/3dgs/lib/python3.10/site-packages/transformers/configuration_utils.py:617\u001b[0m, in \u001b[0;36mPretrainedConfig.get_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    615\u001b[0m original_kwargs \u001b[39m=\u001b[39m copy\u001b[39m.\u001b[39mdeepcopy(kwargs)\n\u001b[1;32m    616\u001b[0m \u001b[39m# Get config dict associated with the base config file\u001b[39;00m\n\u001b[0;32m--> 617\u001b[0m config_dict, kwargs \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49m_get_config_dict(pretrained_model_name_or_path, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    618\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m_commit_hash\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m config_dict:\n\u001b[1;32m    619\u001b[0m     original_kwargs[\u001b[39m\"\u001b[39m\u001b[39m_commit_hash\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m config_dict[\u001b[39m\"\u001b[39m\u001b[39m_commit_hash\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m/media/guest/Elephant/conda_space/envs/3dgs/lib/python3.10/site-packages/transformers/configuration_utils.py:672\u001b[0m, in \u001b[0;36mPretrainedConfig._get_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    668\u001b[0m configuration_file \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mpop(\u001b[39m\"\u001b[39m\u001b[39m_configuration_file\u001b[39m\u001b[39m\"\u001b[39m, CONFIG_NAME)\n\u001b[1;32m    670\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    671\u001b[0m     \u001b[39m# Load from local folder or from cache or download from model Hub and cache\u001b[39;00m\n\u001b[0;32m--> 672\u001b[0m     resolved_config_file \u001b[39m=\u001b[39m cached_file(\n\u001b[1;32m    673\u001b[0m         pretrained_model_name_or_path,\n\u001b[1;32m    674\u001b[0m         configuration_file,\n\u001b[1;32m    675\u001b[0m         cache_dir\u001b[39m=\u001b[39;49mcache_dir,\n\u001b[1;32m    676\u001b[0m         force_download\u001b[39m=\u001b[39;49mforce_download,\n\u001b[1;32m    677\u001b[0m         proxies\u001b[39m=\u001b[39;49mproxies,\n\u001b[1;32m    678\u001b[0m         resume_download\u001b[39m=\u001b[39;49mresume_download,\n\u001b[1;32m    679\u001b[0m         local_files_only\u001b[39m=\u001b[39;49mlocal_files_only,\n\u001b[1;32m    680\u001b[0m         use_auth_token\u001b[39m=\u001b[39;49muse_auth_token,\n\u001b[1;32m    681\u001b[0m         user_agent\u001b[39m=\u001b[39;49muser_agent,\n\u001b[1;32m    682\u001b[0m         revision\u001b[39m=\u001b[39;49mrevision,\n\u001b[1;32m    683\u001b[0m         subfolder\u001b[39m=\u001b[39;49msubfolder,\n\u001b[1;32m    684\u001b[0m         _commit_hash\u001b[39m=\u001b[39;49mcommit_hash,\n\u001b[1;32m    685\u001b[0m     )\n\u001b[1;32m    686\u001b[0m     commit_hash \u001b[39m=\u001b[39m extract_commit_hash(resolved_config_file, commit_hash)\n\u001b[1;32m    687\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mEnvironmentError\u001b[39;00m:\n\u001b[1;32m    688\u001b[0m     \u001b[39m# Raise any environment error raise by `cached_file`. It will have a helpful error message adapted to\u001b[39;00m\n\u001b[1;32m    689\u001b[0m     \u001b[39m# the original exception.\u001b[39;00m\n",
      "File \u001b[0;32m/media/guest/Elephant/conda_space/envs/3dgs/lib/python3.10/site-packages/transformers/utils/hub.py:452\u001b[0m, in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, use_auth_token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash)\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m _raise_exceptions_for_missing_entries \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m _raise_exceptions_for_connection_errors:\n\u001b[1;32m    451\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 452\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mEnvironmentError\u001b[39;00m(\n\u001b[1;32m    453\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mWe couldn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt connect to \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mHUGGINGFACE_CO_RESOLVE_ENDPOINT\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m to load this file, couldn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt find it in the\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    454\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m cached files and it looks like \u001b[39m\u001b[39m{\u001b[39;00mpath_or_repo_id\u001b[39m}\u001b[39;00m\u001b[39m is not the path to a directory containing a file named\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    455\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00mfull_filename\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mCheckout your internet connection or see how to run the library in offline mode at\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    456\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\u001b[39mhttps://huggingface.co/docs/transformers/installation#offline-mode\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    457\u001b[0m     )\n\u001b[1;32m    458\u001b[0m \u001b[39mexcept\u001b[39;00m EntryNotFoundError:\n\u001b[1;32m    459\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m _raise_exceptions_for_missing_entries:\n",
      "\u001b[0;31mOSError\u001b[0m: We couldn't connect to 'https://huggingface.co' to load this file, couldn't find it in the cached files and it looks like xinlai/LISA-7B-v1-explanatory is not the path to a directory containing a file named config.json.\nCheckout your internet connection or see how to run the library in offline mode at 'https://huggingface.co/docs/transformers/installation#offline-mode'."
     ]
    }
   ],
   "source": [
    "from lisa.lisa_pipeline import LISAPipeline\n",
    "from PIL import Image\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "lisa_model_type = \"xinlai/LISA-7B-v1-explanatory\"\n",
    "lisa_conv_type = \"llava_llama_2\"\n",
    "lisa_pipeline = LISAPipeline(lisa_model_type, local_rank=0, load_in_4bit=False, load_in_8bit=True, conv_type=lisa_conv_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_root = 'data/nerf_llff_data/room/images_4'\n",
    "image_names = os.listdir(images_root)\n",
    "image_names = [image_name for idx, image_name in enumerate(image_names) if idx % 8 == 0]\n",
    "image_paths = [os.path.join(images_root, image_name) for image_name in image_names]\n",
    "prompt = 'what can be used to play videos'\n",
    "lisa_text_prompt = f'Can you segment {prompt}?'\n",
    "save_path = f'output/lisa/room/{prompt}'\n",
    "os.makedirs(save_path, exist_ok=True)\n",
    "# image_names = os.listdir(images_root)\n",
    "# image_paths = [os.path.join(images_root, name) for name in image_names]\n",
    "# images = [Image.open(path) for path in image_paths]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DJI_20200226_143850_006.png',\n",
       " 'DJI_20200226_143901_419.png',\n",
       " 'DJI_20200226_143912_008.png',\n",
       " 'DJI_20200226_143926_241.png',\n",
       " 'DJI_20200226_143938_168.png',\n",
       " 'DJI_20200226_143948_113.png']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 1/6 [00:01<00:07,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text_output:  <s>[INST] <<SYS>>You are a helpful language and vision assistant. You are able to understand the visual content that the user provides, and assist the user with a variety of tasks using natural language.<</SYS>> <im_start> <im_end> Can you segment what can be used to play videos? [/INST] Sure, it is [SEG] .</s>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 2/6 [00:03<00:06,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text_output:  <s>[INST] <<SYS>>You are a helpful language and vision assistant. You are able to understand the visual content that the user provides, and assist the user with a variety of tasks using natural language.<</SYS>> <im_start> <im_end> Can you segment what can be used to play videos? [/INST] Sure, it is [SEG] .</s>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 3/6 [00:04<00:04,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text_output:  <s>[INST] <<SYS>>You are a helpful language and vision assistant. You are able to understand the visual content that the user provides, and assist the user with a variety of tasks using natural language.<</SYS>> <im_start> <im_end> Can you segment what can be used to play videos? [/INST] Sure, it is [SEG] .</s>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 4/6 [00:06<00:03,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text_output:  <s>[INST] <<SYS>>You are a helpful language and vision assistant. You are able to understand the visual content that the user provides, and assist the user with a variety of tasks using natural language.<</SYS>> <im_start> <im_end> Can you segment what can be used to play videos? [/INST] Sure, it is [SEG] .</s>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 5/6 [00:07<00:01,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text_output:  <s>[INST] <<SYS>>You are a helpful language and vision assistant. You are able to understand the visual content that the user provides, and assist the user with a variety of tasks using natural language.<</SYS>> <im_start> <im_end> Can you segment what can be used to play videos? [/INST] Sure, it is [SEG] .</s>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:09<00:00,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text_output:  <s>[INST] <<SYS>>You are a helpful language and vision assistant. You are able to understand the visual content that the user provides, and assist the user with a variety of tasks using natural language.<</SYS>> <im_start> <im_end> Can you segment what can be used to play videos? [/INST] Sure, it is [SEG] . [SEG] .</s>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(len(image_paths))):\n",
    "    image_name = image_names[i]\n",
    "    image_path = image_paths[i]\n",
    "    image = Image.open(image_path)\n",
    "    result_list, mask_result_list, mask_list, mask_rgb_list, output_str = lisa_pipeline(lisa_text_prompt, image=image)\n",
    "    save_name = image_name.split('.')[0] + '.png'\n",
    "    Image.fromarray(mask_list[0]).save(os.path.join(save_path, save_name))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/transformers/generation/utils.py:1270: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation )\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text_output:  <s>[INST] <<SYS>>You are a helpful language and vision assistant. You are able to understand the visual content that the user provides, and assist the user with a variety of tasks using natural language.<</SYS>> <im_start> <im_end> Can you segment the biggest tree? [/INST] Sure, [SEG] .</s>\n"
     ]
    }
   ],
   "source": [
    "result_list, mask_result_list, mask_list, mask_rgb_list, output_str = lisa_pipeline(lisa_text_prompt, image=images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(756, 1008)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_list[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=1 size=1008x756>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image.fromarray(mask_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
